{
  "rnn_evaluation": {
    "model_name": "RNN (Self-Attention + LayerNorm)",
    "model_features": "Self-Attention + Layer Normalization + Label Smoothing + Warmup Scheduler",
    "accuracy": 0.6290224650880388,
    "precision_macro": 0.6468168868959504,
    "recall_macro": 0.6217309078316409,
    "f1_macro": 0.6325098475659577,
    "precision_weighted": 0.6336872277443495,
    "recall_weighted": 0.6290224650880388,
    "f1_weighted": 0.6291608601939915,
    "precision_per_class": [
      0.625,
      0.6649214659685864,
      0.6952789699570815,
      0.6666666666666666,
      0.5792880258899676,
      0.649746192893401
    ],
    "recall_per_class": [
      0.5935251798561151,
      0.6649214659685864,
      0.5977859778597786,
      0.6233766233766234,
      0.6741996233521658,
      0.5765765765765766
    ],
    "f1_per_class": [
      0.6088560885608856,
      0.6649214659685864,
      0.6428571428571429,
      0.6442953020134228,
      0.6231505657093125,
      0.6109785202863962
    ],
    "confusion_matrix": [
      [
        165,
        12,
        11,
        6,
        76,
        8
      ],
      [
        12,
        127,
        3,
        7,
        33,
        9
      ],
      [
        3,
        15,
        162,
        14,
        68,
        9
      ],
      [
        6,
        5,
        18,
        96,
        23,
        6
      ],
      [
        60,
        29,
        32,
        15,
        358,
        37
      ],
      [
        18,
        3,
        7,
        6,
        60,
        128
      ]
    ],
    "class_names": [
      "Anger",
      "Fear",
      "Joy",
      "Love",
      "Neutral",
      "Sad"
    ]
  },
  "bilstm_evaluation": {
    "model_name": "BiLSTM (64H-1L-Bidirectional)",
    "model_features": "Bidirectional LSTM + Optimized Hyperparameters",
    "accuracy": 0.6454159077109897,
    "precision_macro": 0.6536633688990198,
    "recall_macro": 0.6595057839640301,
    "f1_macro": 0.656115086947295,
    "precision_weighted": 0.6460619366698978,
    "recall_weighted": 0.6454159077109897,
    "f1_weighted": 0.6453617734383469,
    "precision_per_class": [
      0.6268115942028986,
      0.6717948717948717,
      0.7108433734939759,
      0.6686746987951807,
      0.6140684410646388,
      0.6297872340425532
    ],
    "recall_per_class": [
      0.6223021582733813,
      0.6858638743455497,
      0.6531365313653137,
      0.7207792207792207,
      0.608286252354049,
      0.6666666666666666
    ],
    "f1_per_class": [
      0.6245487364620939,
      0.6787564766839378,
      0.6807692307692308,
      0.69375,
      0.6111636707663197,
      0.6477024070021882
    ],
    "confusion_matrix": [
      [
        173,
        17,
        7,
        10,
        62,
        9
      ],
      [
        13,
        131,
        6,
        5,
        26,
        10
      ],
      [
        7,
        11,
        177,
        13,
        55,
        8
      ],
      [
        9,
        0,
        13,
        111,
        17,
        4
      ],
      [
        61,
        32,
        40,
        19,
        323,
        56
      ],
      [
        13,
        4,
        6,
        8,
        43,
        148
      ]
    ],
    "class_names": [
      "Anger",
      "Fear",
      "Joy",
      "Love",
      "Neutral",
      "Sad"
    ]
  },
  "training_comparison": {
    "rnn_training_time": 51.588497161865234,
    "bilstm_training_time": 19.063238859176636,
    "rnn_best_val_accuracy": 65.87735276259866,
    "bilstm_best_val_accuracy": 66.24165148755313,
    "rnn_parameters": 63623,
    "bilstm_parameters": 85766,
    "rnn_epochs": 40,
    "bilstm_epochs": 30,
    "rnn_config": {
      "input_size": 100,
      "hidden_size": 128,
      "num_layers": 2,
      "num_classes": 6,
      "dropout": 0.3,
      "learning_rate": 0.001,
      "batch_size": 32,
      "num_epochs": 40,
      "weight_decay": 1e-05,
      "optimizer": "adamw",
      "scheduler": "warmup_plateau",
      "label_smoothing": 0.1,
      "gradient_clipping": 2.0,
      "warmup_epochs": 3,
      "warmup_lr": 1e-06
    },
    "bilstm_config": {
      "input_size": 100,
      "hidden_size": 64,
      "num_layers": 1,
      "num_classes": 6,
      "dropout": 0.2,
      "learning_rate": 0.002,
      "batch_size": 64,
      "num_epochs": 30,
      "weight_decay": 0.0001,
      "optimizer": "adam",
      "scheduler": "reduce_lr_on_plateau",
      "gradient_clipping": 1.0
    }
  },
  "summary": {
    "best_model": "BiLSTM (Optimized)",
    "accuracy_difference": 0.016393442622950838,
    "f1_difference": 0.023605239381337295,
    "rnn_features": "Self-Attention + Layer Normalization + Enhanced Training",
    "bilstm_features": "Bidirectional + Optimized Architecture"
  }
}